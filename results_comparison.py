#!/usr/bin/env python3
"""
Visual comparison of all approaches for DV inclusion in factor analysis
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

# Results from all approaches
results = {
    'Approach': [
        'Theory-Based\nEFA',
        'Data-Driven\n(no DV)',
        'Data-Driven\n(with DV)',
        'Manual\nSEM/MIMIC',
        'True\nSEM/MIMIC'
    ],
    'R_squared': [0.117, 0.074, 0.078, 0.066, np.nan],  # True SEM R¬≤ not comparable
    'Adj_R_squared': [0.067, 0.025, 0.029, 0.053, np.nan],
    'Prosocial_Significant': [True, False, False, True, True],
    'Income_Significant': [True, True, True, True, True],
    'Theoretical_Rigor': [2, 1, 1, 4, 5]  # 1-5 scale
}

df = pd.DataFrame(results)

# Create subplots
fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(14, 10))
fig.suptitle('Comparison of All Approaches: Including DV in Factor Analysis', fontsize=16, fontweight='bold')

# 1. R-squared comparison
x_pos = np.arange(len(df['Approach'][:4]))  # Exclude True SEM for R¬≤
r2_vals = df['R_squared'][:4]
adj_r2_vals = df['Adj_R_squared'][:4]

bars1 = ax1.bar(x_pos - 0.2, r2_vals, 0.4, label='R¬≤', alpha=0.8, color='steelblue')
bars2 = ax1.bar(x_pos + 0.2, adj_r2_vals, 0.4, label='Adj-R¬≤', alpha=0.8, color='lightcoral')

ax1.set_xlabel('Approach')
ax1.set_ylabel('R¬≤')
ax1.set_title('Model Performance (R¬≤)')
ax1.set_xticks(x_pos)
ax1.set_xticklabels(df['Approach'][:4], rotation=45, ha='right')
ax1.legend()
ax1.grid(True, alpha=0.3)

# Add value labels on bars
for bar in bars1:
    height = bar.get_height()
    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.005,
             f'{height:.3f}', ha='center', va='bottom', fontsize=9)
for bar in bars2:
    height = bar.get_height()
    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.005,
             f'{height:.3f}', ha='center', va='bottom', fontsize=9)

# 2. Predictor significance
prosocial_sig = df['Prosocial_Significant'].astype(int)
income_sig = df['Income_Significant'].astype(int)

x_pos_all = np.arange(len(df['Approach']))
bars3 = ax2.bar(x_pos_all - 0.2, prosocial_sig, 0.4, label='Prosocial Factor', alpha=0.8, color='green')
bars4 = ax2.bar(x_pos_all + 0.2, income_sig, 0.4, label='Income', alpha=0.8, color='orange')

ax2.set_xlabel('Approach')
ax2.set_ylabel('Significant (1) or Not (0)')
ax2.set_title('Predictor Significance')
ax2.set_xticks(x_pos_all)
ax2.set_xticklabels(df['Approach'], rotation=45, ha='right')
ax2.legend()
ax2.set_ylim(0, 1.2)
ax2.grid(True, alpha=0.3)

# 3. Theoretical rigor
bars5 = ax3.bar(x_pos_all, df['Theoretical_Rigor'], alpha=0.8, color='purple')
ax3.set_xlabel('Approach')
ax3.set_ylabel('Theoretical Rigor (1-5)')
ax3.set_title('Theoretical Correctness')
ax3.set_xticks(x_pos_all)
ax3.set_xticklabels(df['Approach'], rotation=45, ha='right')
ax3.grid(True, alpha=0.3)

# Add value labels
for bar in bars5:
    height = bar.get_height()
    ax3.text(bar.get_x() + bar.get_width()/2., height + 0.05,
             f'{int(height)}', ha='center', va='bottom', fontsize=10)

# 4. Key findings summary
ax4.axis('off')
summary_text = """
KEY FINDINGS:

üèÜ BEST PERFORMANCE: Theory-Based EFA
   ‚Ä¢ R¬≤ = 0.117, significant prosocial factor
   ‚Ä¢ Good balance of theory and performance

üî¨ MOST RIGOROUS: True SEM/MIMIC  
   ‚Ä¢ Simultaneous estimation
   ‚Ä¢ Gold standard methodology

üéØ KEY INSIGHT: SVO is most predictive
   ‚Ä¢ Manual optimization revealed SVO importance
   ‚Ä¢ Standard loading: 0.551 ‚Üí Optimized: 0.962

üí∞ INCOME ALWAYS MATTERS
   ‚Ä¢ Consistent across all approaches
   ‚Ä¢ Economic constraints enable/limit prosociality

üìä THEORY > PURE STATISTICS
   ‚Ä¢ Theory-based outperformed data-driven
   ‚Ä¢ Domain knowledge beats clustering
"""

ax4.text(0.05, 0.95, summary_text, transform=ax4.transAxes, fontsize=10,
         verticalalignment='top', fontfamily='monospace',
         bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))

plt.tight_layout()
plt.savefig('approach_comparison.png', dpi=300, bbox_inches='tight')
plt.show()

# Create a detailed comparison table
print("\n" + "="*80)
print("DETAILED COMPARISON TABLE")
print("="*80)

comparison_data = {
    'Approach': [
        'Theory-Based EFA',
        'Data-Driven (no DV)',
        'Data-Driven (with DV)', 
        'Manual SEM/MIMIC',
        'True SEM/MIMIC'
    ],
    'Method': [
        'EFA bundles ‚Üí Regression',
        'EFA clusters ‚Üí Regression',
        'EFA clusters+DV ‚Üí Regression',
        'Optimize loadings for DV',
        'Simultaneous estimation'
    ],
    'R¬≤': [0.117, 0.074, 0.078, 0.066, 'N/A'],
    'Prosocial Œ≤': ['+2.25**', 'None', 'None', '+1.51*', '+0.19'],
    'Income Œ≤': ['+1.74*', '+1.68*', '+1.68*', '+1.75*', '+0.21'],
    'Advantage': [
        'Best performance',
        'Data-driven discovery',
        'Modest improvement',
        'Optimal factor weights',
        'Theoretically correct'
    ],
    'Limitation': [
        'Two-stage process',
        'No personality effects',
        'Still weak effects',
        'Complex implementation',
        'Implementation challenges'
    ]
}

comp_df = pd.DataFrame(comparison_data)
print(comp_df.to_string(index=False))

print("\n" + "="*80)
print("RECOMMENDATIONS")
print("="*80)
print("üìù FOR YOUR PAPER:")
print("   ‚Üí Use Theory-Based EFA results (R¬≤ = 0.117)")
print("   ‚Üí Report Manual SEM/MIMIC as robustness check")
print("   ‚Üí Mention True SEM as gold standard")
print("")
print("üîç KEY INSIGHT:")
print("   ‚Üí Both personality AND income matter for prosocial behavior")
print("   ‚Üí SVO is the most behaviorally relevant personality measure")
print("   ‚Üí Theory-driven approach beats pure statistical clustering")
print("")
print("üéØ PROFESSOR'S INTENT ACHIEVED:")
print("   ‚Üí Successfully included DV in factor modeling")
print("   ‚Üí Found meaningful personality ‚Üí behavior relationships")
print("   ‚Üí Validated theoretical framework empirically") 